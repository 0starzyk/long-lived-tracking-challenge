/*****************************************************************************\
* (c) Copyright 2000-2018 CERN for the benefit of the LHCb Collaboration      *
*                                                                             *
* This software is distributed under the terms of the GNU General Public      *
* Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   *
*                                                                             *
* In applying this licence, CERN does not waive the privileges and immunities *
* granted to it by virtue of its status as an Intergovernmental Organization  *
* or submit itself to any jurisdiction.                                       *
\*****************************************************************************/
// Class: ReadMLP_3
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : MLP::MLP_3
TMVA Release   : 4.2.1         [262657]
ROOT Release   : 6.06/00       [394752]
Creator        : hyin
Date           : Thu May 19 17:43:30 2016
Host           : Linux lcgapp-slc6-x86-64-7.cern.ch 2.6.32-573.3.1.el6.x86_64 #1 SMP Fri Aug 14 10:45:09 CEST 2015
x86_64 x86_64 x86_64 GNU/Linux Dir            : /afs/cern.ch/work/h/hyin/workspace/GhostTrack/Upgrade_train/Sigmoid
Training events: 2990958
Analysis type  : [Classification]


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
NCycles: "600" [Number of training cycles]
HiddenLayers: "N+5" [Specification of hidden layer architecture]
NeuronType: "sigmoid" [Neuron activation function type]
EstimatorType: "CE" [MSE (Mean Square Estimator) for Gaussian Likelihood or CE(Cross-Entropy) for Bernoulli Likelihood]
V: "False" [Verbose output (short form of "VerbosityLevel" below - overrides the latter one)]
VarTransform: "N" [List of variable transformations performed before training, e.g.,
"D_Background,P_Signal,G,N_AllClasses" for: "Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for
the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is
assumed)"] H: "False" [Print method-specific help message] CreateMVAPdfs: "True" [Create PDFs for classifier outputs
(signal and background)] TestRate: "5" [Test for overtraining performed at each #th epochs] UseRegulator: "False" [Use
regulator to avoid over-training] # Default: RandomSeed: "1" [Random seed for initial synapse weights (0 means unique
seed for each run; default value '1')] NeuronInputType: "sum" [Neuron input function type] VerbosityLevel: "Default"
[Verbosity level] IgnoreNegWeightsInTraining: "False" [Events with negative weights are ignored in the training (but are
included for testing and performance evaluation)] TrainingMethod: "BP" [Train with Back-Propagation (BP), BFGS Algorithm
(BFGS), or Genetic Algorithm (GA - slower and worse)] LearningRate: "2.000000e-02" [ANN learning rate parameter]
DecayRate: "1.000000e-02" [Decay rate for learning parameter]
EpochMonitoring: "False" [Provide epoch-wise monitoring plots according to TestRate (caution: causes big ROOT output
file!)] Sampling: "1.000000e+00" [Only 'Sampling' (randomly selected) events are trained each epoch] SamplingEpoch:
"1.000000e+00" [Sampling is used for the first 'SamplingEpoch' epochs, afterwards, all events are taken for training]
SamplingImportance: "1.000000e+00" [ The sampling weights of events in epochs which successful (worse estimator than
before) are multiplied with SamplingImportance, else they are divided.] SamplingTraining: "True" [The training sample is
sampled] SamplingTesting: "False" [The testing sample is sampled] ResetStep: "50" [How often BFGS should reset history]
Tau: "3.000000e+00" [LineSearch "size step"]
BPMode: "sequential" [Back-propagation learning mode: sequential or batch]
BatchSize: "-1" [Batch size: number of events/batch, only set if in Batch Mode, -1 for BatchSize=number_of_events]
ConvergenceImprove: "1.000000e-30" [Minimum improvement which counts as improvement (<0 means automatic convergence
check is turned off)] ConvergenceTests: "-1" [Number of steps (without improvement) required for convergence (<0 means
automatic convergence check is turned off)] UpdateLimit: "10000" [Maximum times of regulator update] CalculateErrors:
"False" [Calculates inverse Hessian matrix at the end of the training to be able to calculate the uncertainties of an
MVA value] WeightRange: "1.000000e+00" [Take the events for the estimator calculations from small deviations from the
desired value to large deviations only over the weight range]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 17
UpgradeGhostInfo_obsVP        UpgradeGhostInfo_obsVP        UpgradeGhostInfo_obsVP        UpgradeGhostInfo_obsVP 'F'
[3,22] UpgradeGhostInfo_expVP        UpgradeGhostInfo_expVP        UpgradeGhostInfo_expVP        UpgradeGhostInfo_expVP
'F'    [1,28] UpgradeGhostInfo_FitVeloChi2  UpgradeGhostInfo_FitVeloChi2  UpgradeGhostInfo_FitVeloChi2
UpgradeGhostInfo_FitVeloChi2                                    'F'    [1.30166641354e-11,116.130989075]
UpgradeGhostInfo_FitVeloNDoF  UpgradeGhostInfo_FitVeloNDoF  UpgradeGhostInfo_FitVeloNDoF  UpgradeGhostInfo_FitVeloNDoF
'F'    [-1,38] UpgradeGhostInfo_obsFT        UpgradeGhostInfo_obsFT        UpgradeGhostInfo_obsFT UpgradeGhostInfo_obsFT
'F'    [9,15] UpgradeGhostInfo_expFTHitExpectation UpgradeGhostInfo_expFTHitExpectation
UpgradeGhostInfo_expFTHitExpectation UpgradeGhostInfo_expFTHitExpectation                                          'F'
[0,12] UpgradeGhostInfo_FitTChi2     UpgradeGhostInfo_FitTChi2     UpgradeGhostInfo_FitTChi2 UpgradeGhostInfo_FitTChi2
'F'    [0.00224337098189,67.4678115845] UpgradeGhostInfo_FitTNDoF     UpgradeGhostInfo_FitTNDoF
UpgradeGhostInfo_FitTNDoF     UpgradeGhostInfo_FitTNDoF                                       'F'    [2,10]
UpgradeGhostInfo_obsUT        UpgradeGhostInfo_obsUT        UpgradeGhostInfo_obsUT        UpgradeGhostInfo_obsUT 'F'
[0,10] UpgradeGhostInfo_expUTHitExpectation UpgradeGhostInfo_expUTHitExpectation UpgradeGhostInfo_expUTHitExpectation
UpgradeGhostInfo_expUTHitExpectation                                          'F'    [0,8] UpgradeGhostInfo_FitMatchChi2
UpgradeGhostInfo_FitMatchChi2 UpgradeGhostInfo_FitMatchChi2 UpgradeGhostInfo_FitMatchChi2 'F'
[0.00849772524089,110.457511902] UpgradeGhostInfo_UToutlier    UpgradeGhostInfo_UToutlier    UpgradeGhostInfo_UToutlier
UpgradeGhostInfo_UToutlier                                      'F'    [0,2] UpgradeGhostInfo_veloHits
UpgradeGhostInfo_veloHits     UpgradeGhostInfo_veloHits     UpgradeGhostInfo_veloHits 'F'    [95,9416]
UpgradeGhostInfo_utHits       UpgradeGhostInfo_utHits       UpgradeGhostInfo_utHits       UpgradeGhostInfo_utHits 'F'
[113,5736] TRACK_CHI2                    TRACK_CHI2                    TRACK_CHI2                    TRACK_CHI2 'F'
[0.346030950546,140.018478394] TRACK_PT                      TRACK_PT                      TRACK_PT TRACK_PT 'F'
[0.728892683983,1322526.25] TRACK_ETA                     TRACK_ETA                     TRACK_ETA TRACK_ETA 'F'
[1.45450341702,8.93444347382] NSpec 0


============================================================================ */

#include <array>
#include <cmath>
#include <iostream>
#include <string>
#include <vector>

#ifndef IClassifierReader__def
#  define IClassifierReader__def

class IClassifierReader {

public:
  // constructor
  IClassifierReader() : fStatusIsClean( true ) {}
  virtual ~IClassifierReader() {}

  // return classifier response
  virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;

  // returns classifier status
  bool IsStatusClean() const { return fStatusIsClean; }

protected:
  bool fStatusIsClean;
};

#endif

class ReadMLP_3 : public IClassifierReader {

public:
  // constructor
  ReadMLP_3( const std::vector<std::string>& theInputVars )
      : IClassifierReader(), fClassName( "ReadMLP_3" ), fNvars( 17 ), fIsNormalised( false ) {
    // the training input variables
    const char* inputVars[] = {"UpgradeGhostInfo_obsVP",
                               "UpgradeGhostInfo_expVP",
                               "UpgradeGhostInfo_FitVeloChi2",
                               "UpgradeGhostInfo_FitVeloNDoF",
                               "UpgradeGhostInfo_obsFT",
                               "UpgradeGhostInfo_expFTHitExpectation",
                               "UpgradeGhostInfo_FitTChi2",
                               "UpgradeGhostInfo_FitTNDoF",
                               "UpgradeGhostInfo_obsUT",
                               "UpgradeGhostInfo_expUTHitExpectation",
                               "UpgradeGhostInfo_FitMatchChi2",
                               "UpgradeGhostInfo_UToutlier",
                               "UpgradeGhostInfo_veloHits",
                               "UpgradeGhostInfo_utHits",
                               "TRACK_CHI2",
                               "TRACK_PT",
                               "TRACK_ETA"};

    // sanity checks
    if ( theInputVars.size() <= 0 ) {
      std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
      fStatusIsClean = false;
    }

    if ( theInputVars.size() != fNvars ) {
      std::cout << "Problem in class \"" << fClassName
                << "\": mismatch in number of input values: " << theInputVars.size() << " != " << fNvars << std::endl;
      fStatusIsClean = false;
    }

    // validate input variables
    for ( size_t ivar = 0; ivar < theInputVars.size(); ivar++ ) {
      if ( theInputVars[ivar] != inputVars[ivar] ) {
        std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                  << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar]
                  << std::endl;
        fStatusIsClean = false;
      }
    }

    // initialize min and max vectors (for normalisation)
    fVmin[0]  = -1;
    fVmax[0]  = 1;
    fVmin[1]  = -1;
    fVmax[1]  = 1;
    fVmin[2]  = -1;
    fVmax[2]  = 0.99999988079071;
    fVmin[3]  = -1;
    fVmax[3]  = 1;
    fVmin[4]  = -1;
    fVmax[4]  = 1;
    fVmin[5]  = -1;
    fVmax[5]  = 1;
    fVmin[6]  = -1;
    fVmax[6]  = 1;
    fVmin[7]  = -1;
    fVmax[7]  = 1;
    fVmin[8]  = -1;
    fVmax[8]  = 1;
    fVmin[9]  = -1;
    fVmax[9]  = 1;
    fVmin[10] = -1;
    fVmax[10] = 0.99999988079071;
    fVmin[11] = -1;
    fVmax[11] = 1;
    fVmin[12] = -1;
    fVmax[12] = 1;
    fVmin[13] = -1;
    fVmax[13] = 1;
    fVmin[14] = -1;
    fVmax[14] = 1;
    fVmin[15] = -1;
    fVmax[15] = 1;
    fVmin[16] = -1;
    fVmax[16] = 0.99999988079071;

    // initialize input variable types
    fType[0]  = 'F';
    fType[1]  = 'F';
    fType[2]  = 'F';
    fType[3]  = 'F';
    fType[4]  = 'F';
    fType[5]  = 'F';
    fType[6]  = 'F';
    fType[7]  = 'F';
    fType[8]  = 'F';
    fType[9]  = 'F';
    fType[10] = 'F';
    fType[11] = 'F';
    fType[12] = 'F';
    fType[13] = 'F';
    fType[14] = 'F';
    fType[15] = 'F';
    fType[16] = 'F';

    // initialize constants
    Initialize();

    // initialize transformation
    InitTransform();
  }

  // the classifier response
  // "inputValues" is a vector of input values in the same order as the
  // variables given to the constructor
  double GetMvaValue( const std::vector<double>& inputValues ) const override;

private:
  // input variable transformation

  double fMin_1[3][17];
  double fMax_1[3][17];
  void   InitTransform_1();
  void   Transform_1( std::vector<double>& iv, int sigOrBgd ) const;
  void   InitTransform();
  void   Transform( std::vector<double>& iv, int sigOrBgd ) const;

  // common member variables
  const char* fClassName;

  const size_t fNvars;
  size_t       GetNvar() const { return fNvars; }
  char         GetType( int ivar ) const { return fType[ivar]; }

  // normalisation of input variables
  const bool fIsNormalised;
  bool       IsNormalised() const { return fIsNormalised; }
  double     fVmin[17];
  double     fVmax[17];
  double     NormVariable( double x, double xmin, double xmax ) const {
    // normalise to output range: [-1, 1]
    return 2 * ( x - xmin ) / ( xmax - xmin ) - 1.0;
  }

  // type of input variable: 'F' or 'I'
  char fType[17];

  // initialize internal variables
  void   Initialize();
  double GetMvaValue__( const std::vector<double>& inputValues ) const;

  // private members (method specific)

  double ActivationFnc( double x ) const;
  double OutputActivationFnc( double x ) const;

  int    fLayers;
  int    fLayerSize[3];
  double fWeightMatrix0to1[23][18]; // weight matrix from layer 0 to 1
  double fWeightMatrix1to2[1][23];  // weight matrix from layer 1 to 2
};

inline void ReadMLP_3::Initialize() {
  // build network structure
  fLayers       = 3;
  fLayerSize[0] = 18;
  fLayerSize[1] = 23;
  fLayerSize[2] = 1;
  // weight matrix from layer 0 to 1
  fWeightMatrix0to1[0][0]   = -0.827708296272935;
  fWeightMatrix0to1[1][0]   = -22.4371368100605;
  fWeightMatrix0to1[2][0]   = 10.1970357636211;
  fWeightMatrix0to1[3][0]   = 10.3107109157011;
  fWeightMatrix0to1[4][0]   = -19.2018358236487;
  fWeightMatrix0to1[5][0]   = 18.9977984226217;
  fWeightMatrix0to1[6][0]   = 0.937625084472434;
  fWeightMatrix0to1[7][0]   = -0.331547077205289;
  fWeightMatrix0to1[8][0]   = 0.105332016040974;
  fWeightMatrix0to1[9][0]   = -3.64522786648524;
  fWeightMatrix0to1[10][0]  = 13.499938435534;
  fWeightMatrix0to1[11][0]  = -11.8728535399123;
  fWeightMatrix0to1[12][0]  = 1.27694577683893;
  fWeightMatrix0to1[13][0]  = 0.296460254007909;
  fWeightMatrix0to1[14][0]  = -8.01507597797506;
  fWeightMatrix0to1[15][0]  = 0.00797765520363977;
  fWeightMatrix0to1[16][0]  = -5.83848312857936;
  fWeightMatrix0to1[17][0]  = 0.24498281797618;
  fWeightMatrix0to1[18][0]  = -1.91126206815517;
  fWeightMatrix0to1[19][0]  = 0.7792194497314;
  fWeightMatrix0to1[20][0]  = -13.9916077269806;
  fWeightMatrix0to1[21][0]  = -2.11319032936383;
  fWeightMatrix0to1[0][1]   = -4.10715518931357;
  fWeightMatrix0to1[1][1]   = -0.376479535759762;
  fWeightMatrix0to1[2][1]   = -0.185369475588369;
  fWeightMatrix0to1[3][1]   = 5.37496121708539;
  fWeightMatrix0to1[4][1]   = 10.5145404086871;
  fWeightMatrix0to1[5][1]   = -0.238202068384884;
  fWeightMatrix0to1[6][1]   = -0.702580090903737;
  fWeightMatrix0to1[7][1]   = -4.97502151500035;
  fWeightMatrix0to1[8][1]   = -6.35284141656715;
  fWeightMatrix0to1[9][1]   = 8.1688418284899;
  fWeightMatrix0to1[10][1]  = 0.252461903072703;
  fWeightMatrix0to1[11][1]  = -4.78323762051691;
  fWeightMatrix0to1[12][1]  = 1.89109207730101;
  fWeightMatrix0to1[13][1]  = 1.90118673849369;
  fWeightMatrix0to1[14][1]  = -15.7678958187009;
  fWeightMatrix0to1[15][1]  = 7.23094779612936;
  fWeightMatrix0to1[16][1]  = -5.51290908281817;
  fWeightMatrix0to1[17][1]  = 12.1935047395287;
  fWeightMatrix0to1[18][1]  = -5.16335344624284;
  fWeightMatrix0to1[19][1]  = -5.04799340509689;
  fWeightMatrix0to1[20][1]  = 1.94723474114182;
  fWeightMatrix0to1[21][1]  = -0.259170733810388;
  fWeightMatrix0to1[0][2]   = 4.59729701635329;
  fWeightMatrix0to1[1][2]   = -4.51682705403835;
  fWeightMatrix0to1[2][2]   = 1.70197827813837;
  fWeightMatrix0to1[3][2]   = -7.70393389232877;
  fWeightMatrix0to1[4][2]   = 2.1825077992459;
  fWeightMatrix0to1[5][2]   = -6.43759376345822;
  fWeightMatrix0to1[6][2]   = 0.727804538872246;
  fWeightMatrix0to1[7][2]   = 3.41977672658122;
  fWeightMatrix0to1[8][2]   = 10.9598726192421;
  fWeightMatrix0to1[9][2]   = -6.09049863982943;
  fWeightMatrix0to1[10][2]  = 8.0926386244756;
  fWeightMatrix0to1[11][2]  = 4.12722828466812;
  fWeightMatrix0to1[12][2]  = -9.30446643182849;
  fWeightMatrix0to1[13][2]  = -1.884891882872;
  fWeightMatrix0to1[14][2]  = -2.99689681581371;
  fWeightMatrix0to1[15][2]  = 2.06747213354638;
  fWeightMatrix0to1[16][2]  = 3.19660708968361;
  fWeightMatrix0to1[17][2]  = -5.24220563897116;
  fWeightMatrix0to1[18][2]  = 3.15626892841098;
  fWeightMatrix0to1[19][2]  = 0.0988004313383262;
  fWeightMatrix0to1[20][2]  = 10.3474420909698;
  fWeightMatrix0to1[21][2]  = -0.779010259947861;
  fWeightMatrix0to1[0][3]   = 1.96332078352833;
  fWeightMatrix0to1[1][3]   = 31.9111679007392;
  fWeightMatrix0to1[2][3]   = -10.6604157618817;
  fWeightMatrix0to1[3][3]   = -14.1444344708706;
  fWeightMatrix0to1[4][3]   = 12.9695837409063;
  fWeightMatrix0to1[5][3]   = -23.3639256518836;
  fWeightMatrix0to1[6][3]   = 2.34505180981651;
  fWeightMatrix0to1[7][3]   = 4.14505152063943;
  fWeightMatrix0to1[8][3]   = 1.81989401767044;
  fWeightMatrix0to1[9][3]   = -2.57497066274995;
  fWeightMatrix0to1[10][3]  = -29.7838749106793;
  fWeightMatrix0to1[11][3]  = 17.826505470146;
  fWeightMatrix0to1[12][3]  = -1.57317673118567;
  fWeightMatrix0to1[13][3]  = 2.13953687157403;
  fWeightMatrix0to1[14][3]  = 13.8623763046463;
  fWeightMatrix0to1[15][3]  = -2.6018732089904;
  fWeightMatrix0to1[16][3]  = 11.3516453030864;
  fWeightMatrix0to1[17][3]  = -0.541503775398303;
  fWeightMatrix0to1[18][3]  = 6.19205398124711;
  fWeightMatrix0to1[19][3]  = -1.5862641458912;
  fWeightMatrix0to1[20][3]  = 14.609779452718;
  fWeightMatrix0to1[21][3]  = 2.69973983269242;
  fWeightMatrix0to1[0][4]   = 1.26632195619421;
  fWeightMatrix0to1[1][4]   = -0.35651255196397;
  fWeightMatrix0to1[2][4]   = -2.53293048037037;
  fWeightMatrix0to1[3][4]   = 0.209896811914432;
  fWeightMatrix0to1[4][4]   = 1.73978085956127;
  fWeightMatrix0to1[5][4]   = 0.997119442465664;
  fWeightMatrix0to1[6][4]   = 0.923873676180498;
  fWeightMatrix0to1[7][4]   = 5.59282027180362;
  fWeightMatrix0to1[8][4]   = 1.86469198828311;
  fWeightMatrix0to1[9][4]   = 2.52992600794056;
  fWeightMatrix0to1[10][4]  = -0.672008371940938;
  fWeightMatrix0to1[11][4]  = 0.510784287833895;
  fWeightMatrix0to1[12][4]  = 2.08662596560169;
  fWeightMatrix0to1[13][4]  = 0.469697973231399;
  fWeightMatrix0to1[14][4]  = 0.966366937996818;
  fWeightMatrix0to1[15][4]  = -1.22854013970101;
  fWeightMatrix0to1[16][4]  = 1.19576415712622;
  fWeightMatrix0to1[17][4]  = 0.362043613257478;
  fWeightMatrix0to1[18][4]  = -2.79295711568785;
  fWeightMatrix0to1[19][4]  = 2.57646656688724;
  fWeightMatrix0to1[20][4]  = -2.95091261537519;
  fWeightMatrix0to1[21][4]  = -0.996289772181778;
  fWeightMatrix0to1[0][5]   = -11.901312583682;
  fWeightMatrix0to1[1][5]   = 0.248670412059203;
  fWeightMatrix0to1[2][5]   = 1.58092559783121;
  fWeightMatrix0to1[3][5]   = -5.61490971467891;
  fWeightMatrix0to1[4][5]   = -0.95152244850351;
  fWeightMatrix0to1[5][5]   = -0.189778977317013;
  fWeightMatrix0to1[6][5]   = -5.43371262941945;
  fWeightMatrix0to1[7][5]   = -3.16056508292601;
  fWeightMatrix0to1[8][5]   = 4.63599259556042;
  fWeightMatrix0to1[9][5]   = -6.04403370476739;
  fWeightMatrix0to1[10][5]  = 0.779887463222751;
  fWeightMatrix0to1[11][5]  = 0.0680314898745044;
  fWeightMatrix0to1[12][5]  = -1.45598379740258;
  fWeightMatrix0to1[13][5]  = 1.4550174716041;
  fWeightMatrix0to1[14][5]  = -1.73394166399725;
  fWeightMatrix0to1[15][5]  = -1.27620875143488;
  fWeightMatrix0to1[16][5]  = -9.21363096464778;
  fWeightMatrix0to1[17][5]  = -2.38171421087084;
  fWeightMatrix0to1[18][5]  = 2.06826355702971;
  fWeightMatrix0to1[19][5]  = 3.12392723791183;
  fWeightMatrix0to1[20][5]  = -0.114070624859353;
  fWeightMatrix0to1[21][5]  = -0.0791732379932863;
  fWeightMatrix0to1[0][6]   = 3.29241388749316;
  fWeightMatrix0to1[1][6]   = 7.12665859694769;
  fWeightMatrix0to1[2][6]   = -5.34422407878776;
  fWeightMatrix0to1[3][6]   = -4.4240451680131;
  fWeightMatrix0to1[4][6]   = 2.5330959948781;
  fWeightMatrix0to1[5][6]   = -7.77349733415526;
  fWeightMatrix0to1[6][6]   = 2.59348203098012;
  fWeightMatrix0to1[7][6]   = -3.58337083158176;
  fWeightMatrix0to1[8][6]   = 4.28522567363807;
  fWeightMatrix0to1[9][6]   = 0.641707639606303;
  fWeightMatrix0to1[10][6]  = -3.94656010316366;
  fWeightMatrix0to1[11][6]  = 2.57692398345612;
  fWeightMatrix0to1[12][6]  = -6.52791782964221;
  fWeightMatrix0to1[13][6]  = 5.52648132360664;
  fWeightMatrix0to1[14][6]  = -2.20838721341321;
  fWeightMatrix0to1[15][6]  = 2.67585091968768;
  fWeightMatrix0to1[16][6]  = 3.87567434647959;
  fWeightMatrix0to1[17][6]  = -0.698141250961604;
  fWeightMatrix0to1[18][6]  = 6.50563710689746;
  fWeightMatrix0to1[19][6]  = -2.05004655595773;
  fWeightMatrix0to1[20][6]  = 2.30787367036012;
  fWeightMatrix0to1[21][6]  = -3.75108674890025;
  fWeightMatrix0to1[0][7]   = -1.72302991517111;
  fWeightMatrix0to1[1][7]   = 0.336984083872171;
  fWeightMatrix0to1[2][7]   = 4.93277612878644;
  fWeightMatrix0to1[3][7]   = 0.63934628816007;
  fWeightMatrix0to1[4][7]   = -0.797613033304376;
  fWeightMatrix0to1[5][7]   = -1.44669881916064;
  fWeightMatrix0to1[6][7]   = 2.31813943739707;
  fWeightMatrix0to1[7][7]   = -4.70231756621195;
  fWeightMatrix0to1[8][7]   = -2.6297688900709;
  fWeightMatrix0to1[9][7]   = -1.7281483342342;
  fWeightMatrix0to1[10][7]  = 0.962873020837754;
  fWeightMatrix0to1[11][7]  = 0.541212321761622;
  fWeightMatrix0to1[12][7]  = -2.31842158713372;
  fWeightMatrix0to1[13][7]  = 0.266963696263755;
  fWeightMatrix0to1[14][7]  = -0.309639187501955;
  fWeightMatrix0to1[15][7]  = -0.737273633061544;
  fWeightMatrix0to1[16][7]  = -3.23563837714521;
  fWeightMatrix0to1[17][7]  = -0.729366149182718;
  fWeightMatrix0to1[18][7]  = -3.58114121014346;
  fWeightMatrix0to1[19][7]  = -2.98501291612291;
  fWeightMatrix0to1[20][7]  = 1.66861117688628;
  fWeightMatrix0to1[21][7]  = 1.49575719347592;
  fWeightMatrix0to1[0][8]   = 8.43530571061476;
  fWeightMatrix0to1[1][8]   = 1.17576458407621;
  fWeightMatrix0to1[2][8]   = 7.6192872436117;
  fWeightMatrix0to1[3][8]   = -5.94297772396503;
  fWeightMatrix0to1[4][8]   = -0.938118062654669;
  fWeightMatrix0to1[5][8]   = 0.399923393632312;
  fWeightMatrix0to1[6][8]   = 9.63674746792789;
  fWeightMatrix0to1[7][8]   = -5.80370913759989;
  fWeightMatrix0to1[8][8]   = -5.67019536258458;
  fWeightMatrix0to1[9][8]   = -1.06757156719058;
  fWeightMatrix0to1[10][8]  = -0.306736395438205;
  fWeightMatrix0to1[11][8]  = 5.01114177373725;
  fWeightMatrix0to1[12][8]  = -1.12820208289652;
  fWeightMatrix0to1[13][8]  = 1.92270407891107;
  fWeightMatrix0to1[14][8]  = -0.655144518229111;
  fWeightMatrix0to1[15][8]  = -0.103722587421337;
  fWeightMatrix0to1[16][8]  = 2.55457480924722;
  fWeightMatrix0to1[17][8]  = 2.13997543374802;
  fWeightMatrix0to1[18][8]  = 3.30711858109381;
  fWeightMatrix0to1[19][8]  = 0.115262886998389;
  fWeightMatrix0to1[20][8]  = 1.83168195814599;
  fWeightMatrix0to1[21][8]  = -1.13553022560315;
  fWeightMatrix0to1[0][9]   = 0.355584414813937;
  fWeightMatrix0to1[1][9]   = 0.0044123341705084;
  fWeightMatrix0to1[2][9]   = -0.0787319702730038;
  fWeightMatrix0to1[3][9]   = 3.75806493371766;
  fWeightMatrix0to1[4][9]   = -2.02165812429006;
  fWeightMatrix0to1[5][9]   = -0.561852441235381;
  fWeightMatrix0to1[6][9]   = -2.716336782542;
  fWeightMatrix0to1[7][9]   = -1.88603746286028;
  fWeightMatrix0to1[8][9]   = 0.0895289572721439;
  fWeightMatrix0to1[9][9]   = -0.0174401103041543;
  fWeightMatrix0to1[10][9]  = 0.362276277143235;
  fWeightMatrix0to1[11][9]  = -1.03896882836795;
  fWeightMatrix0to1[12][9]  = -0.629498985317243;
  fWeightMatrix0to1[13][9]  = -0.378301857725619;
  fWeightMatrix0to1[14][9]  = 1.94095864317186;
  fWeightMatrix0to1[15][9]  = -0.800864676225859;
  fWeightMatrix0to1[16][9]  = -2.96002236278362;
  fWeightMatrix0to1[17][9]  = 0.0725988555770818;
  fWeightMatrix0to1[18][9]  = -0.0290918179777093;
  fWeightMatrix0to1[19][9]  = -0.475337174529022;
  fWeightMatrix0to1[20][9]  = 0.972478252129379;
  fWeightMatrix0to1[21][9]  = 0.309592996188434;
  fWeightMatrix0to1[0][10]  = -3.27814692875616;
  fWeightMatrix0to1[1][10]  = 7.48404549834475;
  fWeightMatrix0to1[2][10]  = -3.02732881580413;
  fWeightMatrix0to1[3][10]  = 10.3868418806549;
  fWeightMatrix0to1[4][10]  = 3.13419816784187;
  fWeightMatrix0to1[5][10]  = -16.4149536370925;
  fWeightMatrix0to1[6][10]  = 6.02997783850068;
  fWeightMatrix0to1[7][10]  = 2.63720750934501;
  fWeightMatrix0to1[8][10]  = -13.6807089501889;
  fWeightMatrix0to1[9][10]  = -0.84824193469435;
  fWeightMatrix0to1[10][10] = -7.13983965104526;
  fWeightMatrix0to1[11][10] = 2.29953713910734;
  fWeightMatrix0to1[12][10] = 8.63159950343007;
  fWeightMatrix0to1[13][10] = 4.45067761587693;
  fWeightMatrix0to1[14][10] = -4.43510746609107;
  fWeightMatrix0to1[15][10] = 1.38335514473251;
  fWeightMatrix0to1[16][10] = 3.22707591761598;
  fWeightMatrix0to1[17][10] = -5.18728742993365;
  fWeightMatrix0to1[18][10] = 3.53887685072372;
  fWeightMatrix0to1[19][10] = -3.7855547136966;
  fWeightMatrix0to1[20][10] = -2.40879388462697;
  fWeightMatrix0to1[21][10] = 0.854984149581263;
  fWeightMatrix0to1[0][11]  = -2.32137628569353;
  fWeightMatrix0to1[1][11]  = -0.0650660841668972;
  fWeightMatrix0to1[2][11]  = -1.11377142031592;
  fWeightMatrix0to1[3][11]  = 1.10741451661985;
  fWeightMatrix0to1[4][11]  = 0.131201428279948;
  fWeightMatrix0to1[5][11]  = -0.457883467204622;
  fWeightMatrix0to1[6][11]  = -2.05190924315274;
  fWeightMatrix0to1[7][11]  = 1.98444556098907;
  fWeightMatrix0to1[8][11]  = 1.6874665438533;
  fWeightMatrix0to1[9][11]  = 1.44943175673524;
  fWeightMatrix0to1[10][11] = -0.314347816340349;
  fWeightMatrix0to1[11][11] = -0.230719902279078;
  fWeightMatrix0to1[12][11] = 1.75295615970056;
  fWeightMatrix0to1[13][11] = -0.463668653709227;
  fWeightMatrix0to1[14][11] = -0.122786338833819;
  fWeightMatrix0to1[15][11] = 0.211734314314742;
  fWeightMatrix0to1[16][11] = -1.04800041999601;
  fWeightMatrix0to1[17][11] = -0.441792217144146;
  fWeightMatrix0to1[18][11] = -0.768694552383458;
  fWeightMatrix0to1[19][11] = 0.302925270781928;
  fWeightMatrix0to1[20][11] = -1.29482600936795;
  fWeightMatrix0to1[21][11] = -0.356535402504462;
  fWeightMatrix0to1[0][12]  = -0.291336378320432;
  fWeightMatrix0to1[1][12]  = -0.142006808295997;
  fWeightMatrix0to1[2][12]  = -0.427556191794343;
  fWeightMatrix0to1[3][12]  = 0.0985018998798021;
  fWeightMatrix0to1[4][12]  = -0.553943439810021;
  fWeightMatrix0to1[5][12]  = -0.0148693219921662;
  fWeightMatrix0to1[6][12]  = -0.182618086638973;
  fWeightMatrix0to1[7][12]  = 0.984230770741783;
  fWeightMatrix0to1[8][12]  = 1.13474751969631;
  fWeightMatrix0to1[9][12]  = -0.212216332841945;
  fWeightMatrix0to1[10][12] = 0.0626215735076129;
  fWeightMatrix0to1[11][12] = 0.137802815746152;
  fWeightMatrix0to1[12][12] = -0.0232175783736649;
  fWeightMatrix0to1[13][12] = -0.584541972682116;
  fWeightMatrix0to1[14][12] = -0.280436774350178;
  fWeightMatrix0to1[15][12] = 0.452396416007296;
  fWeightMatrix0to1[16][12] = -1.24672939929016;
  fWeightMatrix0to1[17][12] = 0.122735370307866;
  fWeightMatrix0to1[18][12] = 0.157306913018621;
  fWeightMatrix0to1[19][12] = -0.712106081012844;
  fWeightMatrix0to1[20][12] = -0.413516582666058;
  fWeightMatrix0to1[21][12] = 0.229303444318653;
  fWeightMatrix0to1[0][13]  = -0.682148255782926;
  fWeightMatrix0to1[1][13]  = 0.0928907306581941;
  fWeightMatrix0to1[2][13]  = 0.641006633151191;
  fWeightMatrix0to1[3][13]  = 0.84145478707824;
  fWeightMatrix0to1[4][13]  = -0.544906571937068;
  fWeightMatrix0to1[5][13]  = -0.29135066116553;
  fWeightMatrix0to1[6][13]  = 0.579242818804656;
  fWeightMatrix0to1[7][13]  = -1.75934872762266;
  fWeightMatrix0to1[8][13]  = -1.49021286974712;
  fWeightMatrix0to1[9][13]  = -0.2832350692291;
  fWeightMatrix0to1[10][13] = -0.228065009556516;
  fWeightMatrix0to1[11][13] = -0.0411681485322245;
  fWeightMatrix0to1[12][13] = -0.00749457510482917;
  fWeightMatrix0to1[13][13] = 0.419618393060872;
  fWeightMatrix0to1[14][13] = 0.286788856699477;
  fWeightMatrix0to1[15][13] = 1.10571146164638;
  fWeightMatrix0to1[16][13] = 0.922650256091938;
  fWeightMatrix0to1[17][13] = 0.16686838470314;
  fWeightMatrix0to1[18][13] = 1.3405384092521;
  fWeightMatrix0to1[19][13] = -0.246389038791901;
  fWeightMatrix0to1[20][13] = 1.19036002173613;
  fWeightMatrix0to1[21][13] = -3.18878554774856;
  fWeightMatrix0to1[0][14]  = -2.84568130760186;
  fWeightMatrix0to1[1][14]  = -11.8214381263257;
  fWeightMatrix0to1[2][14]  = -0.0112596159816371;
  fWeightMatrix0to1[3][14]  = 6.93099331565222;
  fWeightMatrix0to1[4][14]  = -4.93029667208976;
  fWeightMatrix0to1[5][14]  = 20.2834789655067;
  fWeightMatrix0to1[6][14]  = -5.5811073997131;
  fWeightMatrix0to1[7][14]  = -1.67596716942159;
  fWeightMatrix0to1[8][14]  = -5.88282904502971;
  fWeightMatrix0to1[9][14]  = -2.26023297829668;
  fWeightMatrix0to1[10][14] = 7.5797446769622;
  fWeightMatrix0to1[11][14] = -8.67397808988466;
  fWeightMatrix0to1[12][14] = 8.70139722959468;
  fWeightMatrix0to1[13][14] = -3.72498044583835;
  fWeightMatrix0to1[14][14] = 2.10358292499016;
  fWeightMatrix0to1[15][14] = -0.977426474378291;
  fWeightMatrix0to1[16][14] = -5.19473239212465;
  fWeightMatrix0to1[17][14] = 4.40081463934094;
  fWeightMatrix0to1[18][14] = -4.52446009148544;
  fWeightMatrix0to1[19][14] = 9.24634013695347;
  fWeightMatrix0to1[20][14] = -10.9950841554139;
  fWeightMatrix0to1[21][14] = -0.0112648935097419;
  fWeightMatrix0to1[0][15]  = -3.76203572098558;
  fWeightMatrix0to1[1][15]  = 6.6904198847112;
  fWeightMatrix0to1[2][15]  = 7.00971681534022;
  fWeightMatrix0to1[3][15]  = -10.0614328558991;
  fWeightMatrix0to1[4][15]  = 4.6310314885922;
  fWeightMatrix0to1[5][15]  = 23.1475821986679;
  fWeightMatrix0to1[6][15]  = -6.3085183352506;
  fWeightMatrix0to1[7][15]  = 0.186978950316235;
  fWeightMatrix0to1[8][15]  = 12.9494280867946;
  fWeightMatrix0to1[9][15]  = -5.44987290480276;
  fWeightMatrix0to1[10][15] = 2.6759922457055;
  fWeightMatrix0to1[11][15] = 3.19945235191192;
  fWeightMatrix0to1[12][15] = -5.12251430492896;
  fWeightMatrix0to1[13][15] = 0.198697022525275;
  fWeightMatrix0to1[14][15] = 11.8356004524381;
  fWeightMatrix0to1[15][15] = -0.912287009089683;
  fWeightMatrix0to1[16][15] = -1.22212022043192;
  fWeightMatrix0to1[17][15] = -3.7720247199675;
  fWeightMatrix0to1[18][15] = -3.04293847844372;
  fWeightMatrix0to1[19][15] = 5.07161745815347;
  fWeightMatrix0to1[20][15] = 5.55239639340649;
  fWeightMatrix0to1[21][15] = 9.34034762192581;
  fWeightMatrix0to1[0][16]  = -2.73117492066974;
  fWeightMatrix0to1[1][16]  = -0.225149836125789;
  fWeightMatrix0to1[2][16]  = -1.28250002559656;
  fWeightMatrix0to1[3][16]  = -13.0809694328596;
  fWeightMatrix0to1[4][16]  = -13.3009993297727;
  fWeightMatrix0to1[5][16]  = -4.88058954345165;
  fWeightMatrix0to1[6][16]  = 0.681559403893036;
  fWeightMatrix0to1[7][16]  = -3.24320201432753;
  fWeightMatrix0to1[8][16]  = 0.417552720871072;
  fWeightMatrix0to1[9][16]  = 1.74753727799985;
  fWeightMatrix0to1[10][16] = -0.950497016825004;
  fWeightMatrix0to1[11][16] = -0.390881331168369;
  fWeightMatrix0to1[12][16] = 1.14377178706712;
  fWeightMatrix0to1[13][16] = -1.49030425713992;
  fWeightMatrix0to1[14][16] = -2.52149947528014;
  fWeightMatrix0to1[15][16] = -11.6806584964634;
  fWeightMatrix0to1[16][16] = -6.92426432416388;
  fWeightMatrix0to1[17][16] = -48.8428447618611;
  fWeightMatrix0to1[18][16] = -1.03225275573272;
  fWeightMatrix0to1[19][16] = -1.1573587442762;
  fWeightMatrix0to1[20][16] = -5.50330124328884;
  fWeightMatrix0to1[21][16] = 0.816434979891457;
  fWeightMatrix0to1[0][17]  = 10.2315644804912;
  fWeightMatrix0to1[1][17]  = 12.5577075961681;
  fWeightMatrix0to1[2][17]  = 2.75845647786625;
  fWeightMatrix0to1[3][17]  = 0.120405745326943;
  fWeightMatrix0to1[4][17]  = -1.60497412825013;
  fWeightMatrix0to1[5][17]  = 11.2257965866543;
  fWeightMatrix0to1[6][17]  = 2.23727494315348;
  fWeightMatrix0to1[7][17]  = -2.65890749229834;
  fWeightMatrix0to1[8][17]  = -2.18621249710227;
  fWeightMatrix0to1[9][17]  = -4.6562884273936;
  fWeightMatrix0to1[10][17] = -9.39965796808141;
  fWeightMatrix0to1[11][17] = 4.19674686364322;
  fWeightMatrix0to1[12][17] = -2.76573858655393;
  fWeightMatrix0to1[13][17] = 1.06094529499339;
  fWeightMatrix0to1[14][17] = -5.16812027726681;
  fWeightMatrix0to1[15][17] = -4.42621235230951;
  fWeightMatrix0to1[16][17] = 9.04009705260295;
  fWeightMatrix0to1[17][17] = -2.57607104271232;
  fWeightMatrix0to1[18][17] = -2.45967648242853;
  fWeightMatrix0to1[19][17] = -3.15412004223441;
  fWeightMatrix0to1[20][17] = 1.64638999455928;
  fWeightMatrix0to1[21][17] = 1.16620674214073;
  // weight matrix from layer 1 to 2
  fWeightMatrix1to2[0][0]  = 1.16612645208334;
  fWeightMatrix1to2[0][1]  = 2.42643595765371;
  fWeightMatrix1to2[0][2]  = 1.78248715270545;
  fWeightMatrix1to2[0][3]  = -2.37062526499521;
  fWeightMatrix1to2[0][4]  = 2.40418294480367;
  fWeightMatrix1to2[0][5]  = 4.39710521606528;
  fWeightMatrix1to2[0][6]  = -2.79997629481767;
  fWeightMatrix1to2[0][7]  = -1.75794687186118;
  fWeightMatrix1to2[0][8]  = 1.46083634061515;
  fWeightMatrix1to2[0][9]  = -1.28991192139072;
  fWeightMatrix1to2[0][10] = -2.88264645561972;
  fWeightMatrix1to2[0][11] = 2.87498807287908;
  fWeightMatrix1to2[0][12] = -1.54863365761265;
  fWeightMatrix1to2[0][13] = 3.57489781337075;
  fWeightMatrix1to2[0][14] = 2.75211960183523;
  fWeightMatrix1to2[0][15] = -6.33983140681158;
  fWeightMatrix1to2[0][16] = 1.22778454025502;
  fWeightMatrix1to2[0][17] = -1.53832098961028;
  fWeightMatrix1to2[0][18] = -5.74973552296002;
  fWeightMatrix1to2[0][19] = 1.81931912084306;
  fWeightMatrix1to2[0][20] = 1.71846314253872;
  fWeightMatrix1to2[0][21] = 3.5601731470624;
  fWeightMatrix1to2[0][22] = -2.26594254531017;
}

inline double ReadMLP_3::GetMvaValue__( const std::vector<double>& inputValues ) const {
  std::array<double, 18> fWeights0{{}};
  std::array<double, 23> fWeights1{{}};
  std::array<double, 1>  fWeights2{{}};

  fWeights0.back() = 1.;
  fWeights1.back() = 1.;

  for ( int i = 0; i < fLayerSize[0] - 1; i++ ) fWeights0[i] = inputValues[i];

  // layer 0 to 1
  for ( int o = 0; o < fLayerSize[1] - 1; o++ ) {
    for ( int i = 0; i < fLayerSize[0]; i++ ) {
      double inputVal = fWeightMatrix0to1[o][i] * fWeights0[i];
      fWeights1[o] += inputVal;
    }
    fWeights1[o] = ActivationFnc( fWeights1[o] );
  }
  // layer 1 to 2
  for ( int o = 0; o < fLayerSize[2]; o++ ) {
    for ( int i = 0; i < fLayerSize[1]; i++ ) {
      double inputVal = fWeightMatrix1to2[o][i] * fWeights1[i];
      fWeights2[o] += inputVal;
    }
    fWeights2[o] = OutputActivationFnc( fWeights2[o] );
  }

  return fWeights2[0];
}

double ReadMLP_3::ActivationFnc( double x ) const {
  // sigmoid
  return 1.0 / ( 1.0 + exp( -x ) );
}
double ReadMLP_3::OutputActivationFnc( double x ) const {
  // sigmoid
  return 1.0 / ( 1.0 + exp( -x ) );
}

inline double ReadMLP_3::GetMvaValue( const std::vector<double>& inputValues ) const {
  // classifier response value
  double retval = 0;

  // classifier response, sanity check first
  if ( !IsStatusClean() ) {
    std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
              << " because status is dirty" << std::endl;
    retval = 0;
  } else {
    if ( IsNormalised() ) {
      // normalise variables
      std::vector<double> iV;
      iV.reserve( inputValues.size() );
      int ivar = 0;
      for ( std::vector<double>::const_iterator varIt = inputValues.begin(); varIt != inputValues.end();
            varIt++, ivar++ ) {
        iV.push_back( NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ) );
      }
      Transform( iV, -1 );
      retval = GetMvaValue__( iV );
    } else {
      std::vector<double> iV;
      int                 ivar = 0;
      for ( std::vector<double>::const_iterator varIt = inputValues.begin(); varIt != inputValues.end();
            varIt++, ivar++ ) {
        iV.push_back( *varIt );
      }
      Transform( iV, -1 );
      retval = GetMvaValue__( iV );
    }
  }

  return retval;
}

//_______________________________________________________________________
inline void ReadMLP_3::InitTransform_1() {
  // Normalization transformation, initialisation
  fMin_1[0][0]  = 3;
  fMax_1[0][0]  = 21;
  fMin_1[1][0]  = 3;
  fMax_1[1][0]  = 22;
  fMin_1[2][0]  = 3;
  fMax_1[2][0]  = 22;
  fMin_1[0][1]  = 2;
  fMax_1[0][1]  = 22;
  fMin_1[1][1]  = 1;
  fMax_1[1][1]  = 28;
  fMin_1[2][1]  = 1;
  fMax_1[2][1]  = 28;
  fMin_1[0][2]  = 1.50997034321e-10;
  fMax_1[0][2]  = 116.130989075;
  fMin_1[1][2]  = 1.30166641354e-11;
  fMax_1[1][2]  = 106.350723267;
  fMin_1[2][2]  = 1.30166641354e-11;
  fMax_1[2][2]  = 116.130989075;
  fMin_1[0][3]  = -1;
  fMax_1[0][3]  = 37;
  fMin_1[1][3]  = -1;
  fMax_1[1][3]  = 38;
  fMin_1[2][3]  = -1;
  fMax_1[2][3]  = 38;
  fMin_1[0][4]  = 9;
  fMax_1[0][4]  = 15;
  fMin_1[1][4]  = 9;
  fMax_1[1][4]  = 15;
  fMin_1[2][4]  = 9;
  fMax_1[2][4]  = 15;
  fMin_1[0][5]  = 2;
  fMax_1[0][5]  = 12;
  fMin_1[1][5]  = 0;
  fMax_1[1][5]  = 12;
  fMin_1[2][5]  = 0;
  fMax_1[2][5]  = 12;
  fMin_1[0][6]  = 0.00224337098189;
  fMax_1[0][6]  = 67.4678115845;
  fMin_1[1][6]  = 0.00687870616093;
  fMax_1[1][6]  = 65.6033401489;
  fMin_1[2][6]  = 0.00224337098189;
  fMax_1[2][6]  = 67.4678115845;
  fMin_1[0][7]  = 2;
  fMax_1[0][7]  = 10;
  fMin_1[1][7]  = 2;
  fMax_1[1][7]  = 9;
  fMin_1[2][7]  = 2;
  fMax_1[2][7]  = 10;
  fMin_1[0][8]  = 0;
  fMax_1[0][8]  = 10;
  fMin_1[1][8]  = 0;
  fMax_1[1][8]  = 10;
  fMin_1[2][8]  = 0;
  fMax_1[2][8]  = 10;
  fMin_1[0][9]  = 0;
  fMax_1[0][9]  = 8;
  fMin_1[1][9]  = 0;
  fMax_1[1][9]  = 8;
  fMin_1[2][9]  = 0;
  fMax_1[2][9]  = 8;
  fMin_1[0][10] = 0.0136156035587;
  fMax_1[0][10] = 108.122116089;
  fMin_1[1][10] = 0.00849772524089;
  fMax_1[1][10] = 110.457511902;
  fMin_1[2][10] = 0.00849772524089;
  fMax_1[2][10] = 110.457511902;
  fMin_1[0][11] = 0;
  fMax_1[0][11] = 2;
  fMin_1[1][11] = 0;
  fMax_1[1][11] = 2;
  fMin_1[2][11] = 0;
  fMax_1[2][11] = 2;
  fMin_1[0][12] = 95;
  fMax_1[0][12] = 9416;
  fMin_1[1][12] = 179;
  fMax_1[1][12] = 9416;
  fMin_1[2][12] = 95;
  fMax_1[2][12] = 9416;
  fMin_1[0][13] = 113;
  fMax_1[0][13] = 5736;
  fMin_1[1][13] = 178;
  fMax_1[1][13] = 5736;
  fMin_1[2][13] = 113;
  fMax_1[2][13] = 5736;
  fMin_1[0][14] = 0.346030950546;
  fMax_1[0][14] = 139.62210083;
  fMin_1[1][14] = 0.471094489098;
  fMax_1[1][14] = 140.018478394;
  fMin_1[2][14] = 0.346030950546;
  fMax_1[2][14] = 140.018478394;
  fMin_1[0][15] = 3.15706181526;
  fMax_1[0][15] = 55279.28125;
  fMin_1[1][15] = 0.728892683983;
  fMax_1[1][15] = 1322526.25;
  fMin_1[2][15] = 0.728892683983;
  fMax_1[2][15] = 1322526.25;
  fMin_1[0][16] = 1.45864212513;
  fMax_1[0][16] = 8.43354701996;
  fMin_1[1][16] = 1.45450341702;
  fMax_1[1][16] = 8.93444347382;
  fMin_1[2][16] = 1.45450341702;
  fMax_1[2][16] = 8.93444347382;
}

//_______________________________________________________________________
inline void ReadMLP_3::Transform_1( std::vector<double>& iv, int cls ) const {
  // Normalization transformation
  if ( cls < 0 || cls > 2 ) {
    if ( 2 > 1 )
      cls = 2;
    else
      cls = 2;
  }
  const int nVar = 17;

  std::array<double, nVar> dv;
  for ( int ivar = 0; ivar < nVar; ivar++ ) dv[ivar] = iv[ivar];
  for ( int ivar = 0; ivar < 17; ivar++ ) {
    double offset = fMin_1[cls][ivar];
    double scale  = 1.0 / ( fMax_1[cls][ivar] - fMin_1[cls][ivar] );
    iv[ivar]      = ( dv[ivar] - offset ) * scale * 2 - 1;
  }
}

//_______________________________________________________________________
inline void ReadMLP_3::InitTransform() { InitTransform_1(); }

//_______________________________________________________________________
inline void ReadMLP_3::Transform( std::vector<double>& iv, int sigOrBgd ) const { Transform_1( iv, sigOrBgd ); }
