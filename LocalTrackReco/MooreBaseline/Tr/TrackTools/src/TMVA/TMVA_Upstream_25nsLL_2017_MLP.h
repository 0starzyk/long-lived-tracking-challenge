/*****************************************************************************\
* (c) Copyright 2019 CERN for the benefit of the LHCb Collaboration           *
*                                                                             *
* This software is distributed under the terms of the GNU General Public      *
* Licence version 3 (GPL Version 3), copied verbatim in the file "COPYING".   *
*                                                                             *
* In applying this licence, CERN does not waive the privileges and immunities *
* granted to it by virtue of its status as an Intergovernmental Organization  *
* or submit itself to any jurisdiction.                                       *
\*****************************************************************************/
// Class: ReadMLP_4
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : MLP::MLP
TMVA Release   : 4.2.1         [262657]
ROOT Release   : 6.06/08       [394760]
Creator        : mexu
Date           : Thu Jan 31 10:21:09 2019
Host           : Linux lcgapp-slc6-x86-64-2.cern.ch 2.6.32-504.1.3.el6.x86_64 #1 SMP Wed Nov 12 06:58:35 CET 2014 x86_64
x86_64 x86_64 GNU/Linux Dir            : /afs/cern.ch/work/m/mexu/workspace/Ghost_Study/Final_Verstion Training events:
61727 Analysis type  : [Classification]


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
NCycles: "600" [Number of training cycles]
HiddenLayers: "N+5" [Specification of hidden layer architecture]
NeuronType: "ReLU" [Neuron activation function type]
EstimatorType: "CE" [MSE (Mean Square Estimator) for Gaussian Likelihood or CE(Cross-Entropy) for Bernoulli Likelihood]
V: "False" [Verbose output (short form of "VerbosityLevel" below - overrides the latter one)]
VarTransform: "N" [List of variable transformations performed before training, e.g.,
"D_Background,P_Signal,G,N_AllClasses" for: "Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for
the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is
assumed)"] H: "False" [Print method-specific help message] CreateMVAPdfs: "True" [Create PDFs for classifier outputs
(signal and background)] TestRate: "5" [Test for overtraining performed at each #th epochs] UseRegulator: "False" [Use
regulator to avoid over-training] # Default: RandomSeed: "1" [Random seed for initial synapse weights (0 means unique
seed for each run; default value '1')] NeuronInputType: "sum" [Neuron input function type] VerbosityLevel: "Default"
[Verbosity level] IgnoreNegWeightsInTraining: "False" [Events with negative weights are ignored in the training (but are
included for testing and performance evaluation)] TrainingMethod: "BP" [Train with Back-Propagation (BP), BFGS Algorithm
(BFGS), or Genetic Algorithm (GA - slower and worse)] LearningRate: "2.000000e-02" [ANN learning rate parameter]
DecayRate: "1.000000e-02" [Decay rate for learning parameter]
EpochMonitoring: "False" [Provide epoch-wise monitoring plots according to TestRate (caution: causes big ROOT output
file!)] Sampling: "1.000000e+00" [Only 'Sampling' (randomly selected) events are trained each epoch] SamplingEpoch:
"1.000000e+00" [Sampling is used for the first 'SamplingEpoch' epochs, afterwards, all events are taken for training]
SamplingImportance: "1.000000e+00" [ The sampling weights of events in epochs which successful (worse estimator than
before) are multiplied with SamplingImportance, else they are divided.] SamplingTraining: "True" [The training sample is
sampled] SamplingTesting: "False" [The testing sample is sampled] ResetStep: "50" [How often BFGS should reset history]
Tau: "3.000000e+00" [LineSearch "size step"]
BPMode: "sequential" [Back-propagation learning mode: sequential or batch]
BatchSize: "-1" [Batch size: number of events/batch, only set if in Batch Mode, -1 for BatchSize=number_of_events]
ConvergenceImprove: "1.000000e-30" [Minimum improvement which counts as improvement (<0 means automatic convergence
check is turned off)] ConvergenceTests: "-1" [Number of steps (without improvement) required for convergence (<0 means
automatic convergence check is turned off)] UpdateLimit: "10000" [Maximum times of regulator update] CalculateErrors:
"False" [Calculates inverse Hessian matrix at the end of the training to be able to calculate the uncertainties of an
MVA value] WeightRange: "1.000000e+00" [Take the events for the estimator calculations from small deviations from the
desired value to large deviations only over the weight range]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 11
UpgradeGhostInfo_obsVP        UpgradeGhostInfo_obsVP        UpgradeGhostInfo_obsVP        UpgradeGhostInfo_obsVP 'F'
[3,20] UpgradeGhostInfo_FitVeloChi2  UpgradeGhostInfo_FitVeloChi2  UpgradeGhostInfo_FitVeloChi2
UpgradeGhostInfo_FitVeloChi2                                    'F'    [7.68827579378e-09,84.6936264038]
UpgradeGhostInfo_FitVeloNDoF  UpgradeGhostInfo_FitVeloNDoF  UpgradeGhostInfo_FitVeloNDoF  UpgradeGhostInfo_FitVeloNDoF
'F'    [-1,35] UpgradeGhostInfo_obsUT        UpgradeGhostInfo_obsUT        UpgradeGhostInfo_obsUT UpgradeGhostInfo_obsUT
'F'    [3,9] UpgradeGhostInfo_UToutlier    UpgradeGhostInfo_UToutlier    UpgradeGhostInfo_UToutlier
UpgradeGhostInfo_UToutlier                                      'F'    [0,2] UpgradeGhostInfo_veloHits
UpgradeGhostInfo_veloHits     UpgradeGhostInfo_veloHits     UpgradeGhostInfo_veloHits 'F'    [279,8281]
UpgradeGhostInfo_utHits       UpgradeGhostInfo_utHits       UpgradeGhostInfo_utHits       UpgradeGhostInfo_utHits 'F'
[188,5250] TRACK_CHI2                    TRACK_CHI2                    TRACK_CHI2                    TRACK_CHI2 'F'
[8.60623695189e-05,101.321708679] TRACK_NDOF                    TRACK_NDOF                    TRACK_NDOF TRACK_NDOF 'F'
[2,39] TRACK_PT                      TRACK_PT                      TRACK_PT                      TRACK_PT 'F'
[58.015838623,13455346] TRACK_ETA                     TRACK_ETA                     TRACK_ETA TRACK_ETA 'F'
[1.6037248373,5.47967910767] NSpec 0


============================================================================ */
#include "Kernel/STLExtensions.h"
#include "Kernel/TMV_utils.h"
#include "vdt/exp.h"
#include <array>
#include <string_view>

namespace Data::ReadGhostProbabilityUpstream {
  namespace {
    constexpr auto ActivationFnc       = []( float x ) { return x > 0 ? x : 0; };
    constexpr auto OutputActivationFnc = []( float x ) {
      // sigmoid
      return 1.f / ( 1.f + vdt::fast_expf( -x ) );
    };
    // build network structure
    // weight matrix from layer 0 to 1
    constexpr auto fWeightMatrix0to1 = std::array<std::array<float, 12>, 16>{
        {{-3.86195347838132, 2.13230267611329, 1.98403029650217, 2.22009703266593, -0.720333339343129,
          -0.0655130506270139, -0.0143341976750091, -1.85969885395172, 0.524359191782849, 0.603671351577646,
          7.71621851979678, -1.58493432536452},
         {2.39232947114531, 1.55140011217465, 0.0392357177950116, 1.88641599121126, -0.422960753423788,
          -0.167650847203214, -2.1487375272837, -0.0860259512412715, 1.30363077269789, 2.01204761851406,
          -0.264721872620082, -0.451119303234792},
         {1.36375927199814, 0.27364616124232, 0.675198465406404, 2.18810254706233, -0.0499050190087457,
          1.38404197506928, -0.712624863715598, -2.06496571929309, 0.638957914489223, 1.66527046406203,
          -0.0919190532764695, -0.0299584299039041},
         {1.54671245762513, 1.16013547356653, -0.425871692697383, 1.6095713461582, -0.925885722621889,
          -0.591732196027771, 0.305078302835117, 1.64204125218826, -1.95012069810089, -0.255083456673502,
          0.564476982655723, -1.93941248823941},
         {4.71095391268306, -0.257363181414485, -4.18160558582334, -6.50644288414362, 1.369555231131,
          -0.248895873836066, 1.57711033278133, 2.47308661922102, -2.86611787756547, 0.0136928659173781,
          0.49179439211409, -1.95788753050323},
         {-7.82733405639155, -0.113062237078993, 6.63479418653079, 3.0783765222381, -3.0907387573984,
          -0.220879108825225, -0.317271495733098, -2.31958624105325, 3.60904820822638, 1.17425116809871,
          -0.707723185602966, -0.137743205955684},
         {0.882370235327529, 5.46572025158226, -6.67763743635562, -0.34109909966273, 0.672571598795966,
          0.144351817643782, -0.208770994176204, 1.21832163864695, -5.26267402923677, 0.947536814828722,
          0.714285517596868, -0.267361114076986},
         {1.01175799364528, -5.15395808472679, 1.76819508298944, -4.723741324541, -0.243255108876866,
          -0.511412453394189, 0.959292753524898, 1.19953044115745, 0.959637624771238, 2.35049649193883,
          -0.659790229095952, -3.76504028898009},
         {-3.15830722460982, -0.243195284568564, 1.10079604263536, -1.78334819467621, 1.38451252699092,
          0.16212318653182, 0.323441670058665, -3.0249180182171, 1.4767826792559, 2.92674841014477, -3.02020574685223,
          -1.34283916651112},
         {0.504934900841466, -2.54652487349858, 1.77220911006212, -3.15794893358591, 0.934971304992275,
          -0.402470888053449, 1.66285195441411, 2.50605388100523, -1.32398711606557, 0.988187599648936,
          -2.82178040384078, -1.95374211935931},
         {-1.30698208409992, 2.37798263448807, 2.02539982423876, 1.20189077584987, 1.90492255092567, 0.809001071252987,
          -0.1250490179258, -1.97287586337171, 0.417213095814608, -0.614424810094149, -0.208862186585621,
          0.359865972451283},
         {-0.0305902531871965, -1.28135215510849, -1.49514365651137, 5.7466333439714, -0.478242744853817,
          0.815197588033802, -1.12232148438072, -0.252389612931154, -0.368270488692254, 1.3492121835851,
          4.69784903080792, 0.583943157347614},
         {-0.899356790254107, -0.890121696647927, -0.485433070172272, -2.14625374364162, -1.40435967814943,
          -0.511547766697218, 0.511268952845221, 0.753479969801345, 1.64301433628931, 2.35625099732133,
          -3.1007781084848, -1.70760094014458},
         {-8.87880312090197, 5.41873141668331, 4.19914865522198, 2.75221818441281, -0.731802880154483,
          0.0258593070079808, -0.181342418963136, -6.78229340107522, 6.24541199811453, -0.797890217141528,
          1.09661555854806, 0.592848125773903},
         {-0.870150429707733, 0.621083564596088, 0.452723826607096, 1.86894554522801, 0.331909576328536,
          -1.22409209057161, -1.76247397220365, -0.231770187298075, -1.3904390337156, 1.18491703767062,
          1.16130332353449, -1.33206721089609},
         {-1.11288997057611, -0.349527603683422, 1.25733239998598, -1.39264717129953, 0.0618461174718808,
          -0.659531899525845, -0.319656175625053, 0.291294114780831, 0.472433081211, 0.453866433276139,
          -2.29635903183459, -0.902975060985008}}};

    constexpr auto fWeightMatrix1to2 = std::array<float, 17>{
        {1.15524136394486, 2.51646043139934, -2.40617250374156, -0.195100977470311, -0.772751693184842,
         0.815171991661907, -0.672994299924725, -0.831140188664336, 0.519824615686876, 0.850060118537013,
         -0.890978083677005, -1.21667105887901, 0.596246378539497, 1.04908839280039, 1.46526589876937,
         0.487823800634067, 0.418296736296875}};

    constexpr auto fMin = std::array<float, 11>{
        {3, 7.68827579378e-09, -1, 3, 0, 279, 188, 8.60623695189e-05, 2, 58.015838623, 1.6037248373}};

    constexpr auto fMax =
        std::array<float, 11>{{20, 84.6936264038, 35, 9, 2, 8281, 5250, 101.321708679, 39, 13455346, 5.47967910767}};

    // Normalization transformation
    constexpr auto transformer = TMV::Utils::Transformer{fMin, fMax};

    // the training input variables
    constexpr auto validator = TMV::Utils::Validator{
        "ReadGhostProbabilityUpstream",
        std::tuple{"UpgradeGhostInfo_obsVP", "UpgradeGhostInfo_FitVeloChi2", "UpgradeGhostInfo_FitVeloNDoF",
                   "UpgradeGhostInfo_obsUT", "UpgradeGhostInfo_UToutlier", "UpgradeGhostInfo_veloHits",
                   "UpgradeGhostInfo_utHits", "TRACK_CHI2", "TRACK_NDOF", "TRACK_PT", "TRACK_ETA"}};

    constexpr auto l0To1 = TMV::Utils::Layer{fWeightMatrix0to1, ActivationFnc};
    constexpr auto l1To2 = TMV::Utils::Layer{fWeightMatrix1to2, OutputActivationFnc};
    constexpr auto MVA   = TMV::Utils::MVA{validator, transformer, 0, l0To1, l1To2};
  } // namespace
} // namespace Data::ReadGhostProbabilityUpstream

//_______________________________________________________________________

struct ReadGhostProbabilityUpstream final {

  // constructor
  ReadGhostProbabilityUpstream( LHCb::span<const std::string_view, 11> theInputVars ) {
    Data::ReadGhostProbabilityUpstream::MVA.validate( theInputVars );
  }

  // the classifier response
  // "inputValues" is a vector of input values in the same order as the
  // variables given to the constructor
  static constexpr auto GetMvaValue( LHCb::span<const float, 11> input ) {
    return Data::ReadGhostProbabilityUpstream::MVA( input );
  }
};
